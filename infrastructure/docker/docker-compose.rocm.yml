 
# ROCm-enabled setup for SDNext + LoRA Backend (AMD GPUs)
# 
# Features:
# - AMD GPU acceleration with ROCm
# - Backend API server with dual architecture (app/ + backend/)
# - Frontend served by backend (Vite-built assets)
# - Redis job queue and PostgreSQL database
# - SDNext integration for AI image generation
#
# Usage: docker-compose -f docker-compose.rocm.yml up
# Access: http://localhost:8782 (LoRA Manager), http://localhost:7860 (SDNext)

services:
  redis:
    image: redis:7
    restart: unless-stopped
    ports:
      - '6380:6379'

  postgres:
    image: postgres:15
    restart: unless-stopped
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=lora
    ports:
      - '5433:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # SDNext with ROCm support for AMD GPUs
  sdnext:
    image: disty0/sdnext-rocm:latest
    restart: unless-stopped
    ports:
      - '7860:7860'
    volumes:
      # Mount host model directories under /host to avoid blocking /app
      - /home/anxilinux/DeepVault/models/Stable-diffusion:/host/models/Stable-diffusion
      - /home/anxilinux/DeepVault/models/Diffusers:/host/models/Diffusers
      - /home/anxilinux/DeepVault/models/huggingface:/host/models/huggingface
      - /home/anxilinux/DeepVault/models/VAE:/host/models/VAE
      - /home/anxilinux/DeepVault/models/UNET:/host/models/UNET
      - /home/anxilinux/DeepVault/models/Text-encoder:/host/models/Text-encoder
      - /home/anxilinux/DeepVault/models/Lora:/host/models/Lora
      - /home/anxilinux/DeepVault/models/tunable:/host/models/tunable
      - /home/anxilinux/DeepVault/models/embeddings:/host/models/embeddings
      - /home/anxilinux/DeepVault/models/ONNX:/host/models/ONNX
      - /home/anxilinux/DeepVault/models/styles:/host/models/styles
      - /home/anxilinux/DeepVault/models/yolo:/host/models/yolo
      - /home/anxilinux/DeepVault/models/wildcards:/host/models/wildcards
      - ./sdnext_config:/host/config   # SDNext configuration
      - sdnext_data:/host/repositories # Extensions and repos
      - sdnext_outputs:/host/outputs   # Generated images
      # Mount local cloned sdnext source so container has /app contents pre-populated
      - ./sdnext_src:/app
    # Enable AMD ROCm GPU access without Swarm
    devices:
      - /dev/kfd
      - /dev/dri
    group_add:
      - video
    device_cgroup_rules:
      - 'c 226:* rmw'
      - 'c 238:* rmw'
    security_opt:
      - seccomp:unconfined
    environment:
      # ROCm-optimized SDNext configuration for your setup (mapping style prevents YAML folding issues)
      COMMANDLINE_ARGS: "--listen --port 7860 --api  --cors-origins '*'  --data-dir /host/models --models-dir /host/models/Stable-diffusion "
      # ROCm performance tuning environment variables
      HSA_OVERRIDE_GFX_VERSION: "10.3.0"  # Set to your GPU version (e.g., 10.3.0 for RDNA2, 11.0.0 for RDNA3)
      ROC_ENABLE_PRE_VEGA: "1"             # Enable for older AMD GPUs
      HIP_VISIBLE_DEVICES: "0"              # Use first GPU
      MIOPEN_FIND_MODE: "FAST"              # Faster startup, slightly worse performance
      # Alternative: MIOPEN_FIND_ENFORCE=SEARCH for best performance but slower startup
      MIOPEN_USER_DB_PATH: "/tmp/.miopen"  # MIOpen database path
      # Hugging Face token (set your own or use HF_TOKEN environment variable)
      # HF_TOKEN: "your_huggingface_token_here"
    networks:
      - default
    # Run a tiny entrypoint to mark /app as a safe git directory (prevents "dubious ownership")
    entrypoint:
      - /bin/sh
      - -c
      - "git config --global --add safe.directory /app || true; exec startup.sh $$COMMANDLINE_ARGS"
  # Healthcheck disabled because repeated network checks can create virtual
  # interfaces on the host and trigger NetworkManager events (causes
  # ERR_NETWORK_CHANGED in browser/Electron apps). Re-enable only if you
  # confirm it won't disturb your local network manager.
  # healthcheck:
  #   test: ["CMD", "curl", "-f", "http://localhost:7860/sdapi/v1/options"]
  #   interval: 30s
  #   timeout: 15s
  #   retries: 5
  #   start_period: 240s  # ROCm initialization takes longer than CUDA

  api:
    build:
      context: ../../
      dockerfile: infrastructure/docker/Dockerfile
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - ../../backend:/app/backend
      - ../../app:/app/app
      - /home/anxilinux/DeepVault/models/Lora/collections:/app/loras  # Your actual LoRA directory (mount parent dir for full access)
      - sdnext_outputs:/app/outputs   # Access to generated images
    ports:
      - '8782:8000'
    environment:
      IMPORT_ON_STARTUP: 'True'
      REDIS_URL: "redis://redis:6379/0"
      DATABASE_URL: "postgresql+psycopg://postgres:postgres@postgres:5432/lora"
      # Backend URL for frontend-to-backend communication
      BACKEND_URL: "http://localhost:8782/api/v1"
      # SDNext integration
      SDNEXT_BASE_URL: "http://sdnext:7860"
      SDNEXT_TIMEOUT: "240"             # Longer timeout for ROCm
      SDNEXT_POLL_INTERVAL: "2"        # Slightly slower polling for ROCm
      SDNEXT_DEFAULT_STEPS: "20"       # Standard steps for ROCm
      SDNEXT_DEFAULT_SAMPLER: "DPM++ 2M"
      SDNEXT_DEFAULT_CFG_SCALE: "7.0"
      SDNEXT_OUTPUT_DIR: "/app/outputs"
      # Your specific setup
      LORA_DIRECTORY: "/app/loras"
      # Development settings
      API_KEY: "dev-api-key-123"       # Fixed API key for development
    depends_on:
      sdnext:
        condition: service_started     # SDNext start is sufficient; healthcheck is disabled
      redis:
        condition: service_started
      postgres:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  worker:
    build:
      context: ../../
      dockerfile: infrastructure/docker/Dockerfile
    command: sh -c "rq worker --url $$REDIS_URL default"
    volumes:
      - ../../backend:/app/backend
      - ../../app:/app/app
      - /home/anxilinux/DeepVault/models/Lora:/app/loras  # Your actual LoRA directory
      - sdnext_outputs:/app/outputs
    environment:
      REDIS_URL: "redis://redis:6379/0"
      DATABASE_URL: "postgresql+psycopg://postgres:postgres@postgres:5432/lora"
      # SDNext integration
      SDNEXT_BASE_URL: "http://sdnext:7860"
      SDNEXT_TIMEOUT: "240"
      SDNEXT_POLL_INTERVAL: "2"
      SDNEXT_DEFAULT_STEPS: "20"
      SDNEXT_DEFAULT_SAMPLER: "DPM++ 2M"
      SDNEXT_DEFAULT_CFG_SCALE: "7.0"
      SDNEXT_OUTPUT_DIR: "/app/outputs"
      # Your specific setup
      LORA_DIRECTORY: "/app/loras"
    depends_on:
      sdnext:
        condition: service_started
      redis:
        condition: service_started
      postgres:
        condition: service_started

# Frontend Development Note:
# The LoRA Manager now uses Vite for frontend development. To run the frontend:
# 1. On host: npm install && npm run dev (runs on localhost:5173)
# 2. Frontend serves from app/frontend/static/ with hot reload
# 3. Backend serves built frontend assets in production
# 4. Access the application at http://localhost:8782 (backend serves frontend)

networks:
  default:
    name: lora_backend_rocm_net

volumes:
  postgres_data:
  sdnext_data:
  sdnext_outputs:
